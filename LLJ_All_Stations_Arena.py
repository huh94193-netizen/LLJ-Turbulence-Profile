import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
import re
import os
import glob
import logging
from datetime import datetime

# ================= é…ç½®åŒºåŸŸ =================
DATA_DIR = r'/home/huxun/02_LLJ/exported_data'
OUTPUT_DIR = r'/home/huxun/02_LLJ/result/all_stations_arena'
LOG_DIR = r'/home/huxun/02_LLJ/logs'

# åˆ¤å®šæ ‡å‡†
LLJ_THRESHOLD = 2.0
MIN_JET_HEIGHT = 60      
MAX_JET_HEIGHT = 480
# ===========================================

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(os.path.join(OUTPUT_DIR, 'station_fits'), exist_ok=True) # å­˜æ”¾å•åœºç«™å›¾ç‰‡çš„å­ç›®å½•
os.makedirs(LOG_DIR, exist_ok=True)

# --- 0. é…ç½®æ—¥å¿—ç³»ç»Ÿ ---
def setup_logging():
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(LOG_DIR, f'LLJ_All_Stations_{timestamp}.log')
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    logging.info(f"æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆã€‚æ—¥å¿—æ–‡ä»¶: {log_file}")

# ---------------------------------------------------------
# 1. å®šä¹‰æ‰€æœ‰å‚èµ›é€‰æ‰‹ (æ•°å­¦æ¨¡å‹)
# ---------------------------------------------------------

def model_banta(z, alpha, beta):
    """ [é€‰æ‰‹A] Banta (Wall Jet) """
    z = np.maximum(z, 1e-6)
    val = np.power(z, alpha) * np.exp(beta * (1.0 - z))
    return np.nan_to_num(val)

def model_gaussian(z, sigma):
    """ [é€‰æ‰‹B] æ ‡å‡†é«˜æ–¯ (Symmetric Gaussian) """
    return np.exp(-((z - 1.0)**2) / (2 * sigma**2))

def model_asym_gaussian(z, sigma_down, sigma_up):
    """ [é€‰æ‰‹C] éå¯¹ç§°é«˜æ–¯ (Asymmetric Gaussian) """
    sigma = np.where(z <= 1.0, sigma_down, sigma_up)
    return np.exp(-((z - 1.0)**2) / (2 * sigma**2))

def model_sech(z, width, shape):
    """ [é€‰æ‰‹D] åŒæ›²æ­£å‰² (Sech / Modified Tanh å˜ä½“) """
    return (1.0 / np.cosh((z - 1.0) / width)) ** shape

def model_quadratic(z, k):
    """ [é€‰æ‰‹E] äºŒæ¬¡å‡½æ•° (å€’æ‰£æŠ›ç‰©çº¿) """
    val = 1.0 - k * (z - 1.0)**2
    return np.maximum(val, 0)

# ---------------------------------------------------------
# 2. æé€Ÿç‰ˆæ•°æ®è¯»å–ä¸å½’ä¸€åŒ– (å‘é‡åŒ–åŠ é€Ÿ)
# ---------------------------------------------------------
def read_and_normalize(file_path):
    station_name = os.path.basename(file_path).split('-')[0]
    # logging.info(f"æ­£åœ¨è¯»å–: {station_name}")
    
    # 1. è¯»å–æ–‡ä»¶
    df = None
    encodings = ['utf-8', 'gbk', 'gb18030', 'utf-16']
    for enc in encodings:
        try:
            temp_df = pd.read_csv(file_path, sep='\t', skiprows=12, encoding=enc, engine='python')
            if 'mæ°´å¹³é£é€Ÿ' in str(temp_df.columns):
                df = temp_df
                break
            temp_df = pd.read_csv(file_path, sep='\s+', skiprows=12, encoding=enc, engine='python')
            if 'mæ°´å¹³é£é€Ÿ' in str(temp_df.columns):
                df = temp_df
                break
        except: continue
        
    if df is None:
        logging.error(f"{station_name}: æ— æ³•è¯»å–æ–‡ä»¶ã€‚")
        return None, None
    
    df.columns = [str(c).strip().replace('"', '') for c in df.columns]
    
    # 2. çŸ©é˜µåŒ–æå–
    speed_cols = [c for c in df.columns if 'mæ°´å¹³é£é€Ÿ' in c and 'æœ€å¤§' not in c]
    heights = sorted([int(re.search(r'(\d+)', c).group(1)) for c in speed_cols])
    
    if not heights: return None, None

    n_samples = len(df)
    n_heights = len(heights)
    ws_matrix = np.full((n_samples, n_heights), np.nan)
    
    for i, h in enumerate(heights):
        col = [c for c in df.columns if f'{h}mæ°´å¹³é£é€Ÿ' in c and 'æœ€å¤§' not in c][0]
        ws_matrix[:, i] = pd.to_numeric(df[col], errors='coerce').values
        
    # 3. å‘é‡åŒ–è®¡ç®—
    valid_mask = ~np.isnan(ws_matrix).any(axis=1)
    ws_matrix = ws_matrix[valid_mask]
    
    if len(ws_matrix) == 0: return None, None

    max_indices = np.argmax(ws_matrix, axis=1)
    u_jets = ws_matrix[np.arange(len(ws_matrix)), max_indices]
    z_jets = np.array(heights)[max_indices]
    
    u_bottoms = ws_matrix[:, 0]
    u_tops = ws_matrix[:, -1]
    
    # 4. ç­›é€‰
    cond_h = (z_jets >= MIN_JET_HEIGHT) & (z_jets <= MAX_JET_HEIGHT)
    cond_shear = (u_jets - u_bottoms >= LLJ_THRESHOLD) & (u_jets - u_tops >= LLJ_THRESHOLD)
    final_mask = cond_h & cond_shear
    
    ws_final = ws_matrix[final_mask]
    u_jets_final = u_jets[final_mask]
    z_jets_final = z_jets[final_mask]
    
    if len(ws_final) < 10: # æ ·æœ¬å¤ªå°‘å°±è·³è¿‡
        logging.warning(f"{station_name}: æœ‰æ•ˆæ ·æœ¬ä¸è¶³ ({len(ws_final)})")
        return None, None
    
    # 5. å½’ä¸€åŒ–
    norm_u_matrix = ws_final / u_jets_final[:, np.newaxis]
    z_grid = np.array(heights)[np.newaxis, :] 
    norm_z_matrix = z_grid / z_jets_final[:, np.newaxis]
    
    flat_norm_z = norm_z_matrix.flatten()
    flat_norm_u = norm_u_matrix.flatten()
    
    logging.info(f"{station_name}: æå–æˆåŠŸ (N={len(ws_final)})")
    return flat_norm_z, flat_norm_u

# ---------------------------------------------------------
# 3. å•åœºç«™æ¨¡å‹ç«æŠ€å‡½æ•°
# ---------------------------------------------------------
def run_station_arena(nz, nu, station_name):
    """åœ¨ä¸€ä¸ªåœºç«™æ•°æ®ä¸Šè·‘æ‰€æœ‰æ¨¡å‹ï¼Œè¿”å›ç»“æœåˆ—è¡¨"""
    z_fit = np.linspace(0, 2.5, 200)
    models_res = []

    # å®šä¹‰æ¨¡å‹åˆ—è¡¨ä»¥æ–¹ä¾¿å¾ªç¯
    candidates = [
        {'name': 'Banta', 'func': model_banta, 'p0': [1.0, 1.0], 'bounds': ([0,0], [10,10]), 'color': 'red'},
        {'name': 'Gaussian', 'func': model_gaussian, 'p0': [0.5], 'bounds': None, 'color': 'blue'},
        {'name': 'Asym-Gauss', 'func': model_asym_gaussian, 'p0': [0.4, 0.6], 'bounds': None, 'color': 'green'},
        {'name': 'Sech', 'func': model_sech, 'p0': [0.5, 1.0], 'bounds': None, 'color': 'purple'},
        {'name': 'Quadratic', 'func': model_quadratic, 'p0': [0.5], 'bounds': ([0], [10]), 'color': 'orange'}
    ]
    
    # ç»˜å›¾åˆå§‹åŒ–
    plt.figure(figsize=(10, 8))
    # é™é‡‡æ ·ç»˜å›¾èƒŒæ™¯
    if len(nz) > 5000:
        idx = np.random.choice(len(nz), 5000, replace=False)
        plt.scatter(nu[idx], nz[idx], s=1, color='gray', alpha=0.1, label='Raw Data')
    else:
        plt.scatter(nu, nz, s=1, color='gray', alpha=0.1, label='Raw Data')

    best_rmse = float('inf')
    best_model_name = ""

    for model in candidates:
        try:
            kwargs = {'p0': model['p0'], 'maxfev': 2000}
            if model['bounds']: kwargs['bounds'] = model['bounds']
            
            popt, _ = curve_fit(model['func'], nz, nu, **kwargs)
            rmse = np.sqrt(np.mean((nu - model['func'](nz, *popt))**2))
            
            # è®°å½•ç»“æœ
            res_entry = {
                'Model': model['name'],
                'RMSE': rmse,
                'Params': str(np.round(popt, 3))
            }
            models_res.append(res_entry)
            
            # æ›´æ–°æœ€ä½³
            if rmse < best_rmse:
                best_rmse = rmse
                best_model_name = model['name']

            # ç”»çº¿
            label_txt = f"{model['name']} (RMSE={rmse:.3f})"
            lw = 3 if model['name'] == best_model_name else 1.5 # æœ€ä½³æ¨¡å‹åŠ ç²—æš‚å®šï¼Œåé¢ä¼šè¦†ç›–ï¼Œè¿™é‡Œä¸»è¦ç”»å…¨
            plt.plot(model['func'](z_fit, *popt), z_fit, color=model['color'], lw=2, label=label_txt)

        except:
            continue

    # å®Œå–„ç»˜å›¾
    plt.title(f'Station: {station_name} | Winner: {best_model_name}', fontsize=14)
    plt.xlabel('Normalized Speed')
    plt.ylabel('Normalized Height')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.ylim(0, 2.5)
    
    # ä¿å­˜å›¾ç‰‡
    img_name = f"{station_name}_best_fit.png"
    plt.savefig(os.path.join(OUTPUT_DIR, 'station_fits', img_name), dpi=150)
    plt.close() # å…³é—­ç”»å¸ƒé‡Šæ”¾å†…å­˜

    # è¿”å›æŒ‰ RMSE æ’åºçš„ç»“æœ
    models_res.sort(key=lambda x: x['RMSE'])
    return models_res

# ---------------------------------------------------------
# 4. ä¸»ç¨‹åº
# ---------------------------------------------------------
def main():
    setup_logging()
    
    files = glob.glob(os.path.join(DATA_DIR, '*.txt'))
    if not files:
        logging.error(f"ç›®å½• {DATA_DIR} ä¸‹æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼")
        return
    
    logging.info(f"æ£€æµ‹åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹æ‰¹é‡æ¨¡å‹ç«æŠ€...")
    
    all_station_summary = [] # å­˜å‚¨æ¯ä¸ªåœºç«™çš„å† å†›ä¿¡æ¯
    winner_counts = {}       # ç»Ÿè®¡å„æ¨¡å‹å¤ºå† æ¬¡æ•°

    for idx, f in enumerate(files):
        station_name = os.path.basename(f).split('-')[0]
        # logging.info(f"--- å¤„ç† [{idx+1}/{len(files)}]: {station_name} ---")
        
        nz, nu = read_and_normalize(f)
        if nz is None: continue
        
        # è·‘ç«æŠ€åœº
        results = run_station_arena(nz, nu, station_name)
        
        if results:
            winner = results[0] # RMSE æœ€å°çš„
            second = results[1] if len(results) > 1 else None
            
            # è®°å½•å† å†›
            summary_entry = {
                'Station': station_name,
                'Best_Model': winner['Model'],
                'Best_RMSE': winner['RMSE'],
                'Best_Params': winner['Params'],
                'Second_Model': second['Model'] if second else 'None',
                'Second_RMSE': second['RMSE'] if second else 0,
                'RMSE_Improvement': 0
            }
            
            if second:
                imp = (second['RMSE'] - winner['RMSE']) / second['RMSE'] * 100
                summary_entry['RMSE_Improvement'] = round(imp, 2)
                
            all_station_summary.append(summary_entry)
            
            # ç»Ÿè®¡
            w_name = winner['Model']
            winner_counts[w_name] = winner_counts.get(w_name, 0) + 1
            
            logging.info(f"  -> å† å†›: {w_name} (RMSE={winner['RMSE']:.4f})")
        else:
            logging.warning(f"  -> {station_name} æ‹Ÿåˆå…¨éƒ¨å¤±è´¥")

    # --- 5. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š ---
    if not all_station_summary:
        logging.error("æ²¡æœ‰äº§ç”Ÿä»»ä½•æœ‰æ•ˆç»“æœã€‚")
        return

    df_res = pd.DataFrame(all_station_summary)
    
    # æ’åºï¼šæŒ‰åœºç«™å
    df_res = df_res.sort_values('Station')
    
    # ä¿å­˜ Excel
    out_excel = os.path.join(OUTPUT_DIR, 'All_Stations_Best_Models.xlsx')
    df_res.to_excel(out_excel, index=False)
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*50)
    print(" ğŸ† å…¨åœºç«™æ¨¡å‹ç«æŠ€æ€»å†³èµ›ç»“æœ ğŸ†")
    print("="*50)
    print(f"å¤„ç†åœºç«™æ•°: {len(all_station_summary)}")
    print("\n[å¤ºå† æ¦œå•]")
    sorted_counts = sorted(winner_counts.items(), key=lambda x: x[1], reverse=True)
    for model, count in sorted_counts:
        print(f"  - {model:12s}: å¤ºå†  {count} æ¬¡")
    
    print("\n[è¯¦ç»†ç»“æœå·²ä¿å­˜]")
    print(f"  - Excel æ€»è¡¨: {out_excel}")
    print(f"  - å•ç«™æ‹Ÿåˆå›¾: {os.path.join(OUTPUT_DIR, 'station_fits')}")
    print("="*50)
    
    logging.info("ä»»åŠ¡å…¨éƒ¨å®Œæˆã€‚")

if __name__ == "__main__":
    main()